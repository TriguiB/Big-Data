services:
  # Définition de Spark Master et Worker
  spark-master:
    image: bitnami/spark:latest
    container_name: spark-master
    ports:
      - "8080:8080"  # UI Spark
      - "7077:7077"  # Port maître Spark
    environment:
      - SPARK_MODE=master

  spark-worker-1:
    image: bitnami/spark:latest
    container_name: spark-worker-1
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077

  spark-worker-2:
    image: bitnami/spark:latest
    container_name: spark-worker-2
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077

  mongodb:
    image: mongo:6.0
    container_name: mongodb
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db

  app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: app
    depends_on:
      - spark-master
      - mongodb
    volumes:
      - .:/app
    environment:
      - MONGO_URI=mongodb://mongodb:27017/github_issues
      - MLFLOW_TRACKING_URI=http://mlflow:5000  # Assurez-vous d'utiliser l'URL correcte de MLflow
    command: ["python", "your_script.py"]
    working_dir: /app
    user: root

  mlflow:
    image: python:3.8-slim  # Ou utilisez l'image Docker officielle de MLflow
    container_name: mlflow
    ports:
      - "5000:5000"  # Port pour l'interface web MLflow
    volumes:
      - mlruns:/mlflow/mlruns  # Répertoire pour stocker les expérimentations
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000  # URI pour les expérimentations
    command: ["mlflow", "ui", "--host", "0.0.0.0"]

volumes:
  mongodb_data:
  mlruns:

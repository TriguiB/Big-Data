{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-22 19:22:06.504125: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-22 19:22:06.762962: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740252126.865501   19301 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740252126.894072   19301 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-22 19:22:07.135000: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution des classes dans l'ensemble complet :\n",
      "duration_class\n",
      "5    23.744574\n",
      "3    20.150176\n",
      "1    19.717707\n",
      "4    18.817920\n",
      "2    17.569623\n",
      "Name: proportion, dtype: float64\n",
      "Shape of TF-IDF features: (63126, 5000)\n",
      "Shape of dense language features: (63126, 8)\n",
      "Shape of sparse language features: (63126, 8)\n",
      "Shape of combined features: (63126, 5008)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/22 19:22:20 INFO mlflow.tracking.fluent: Experiment with name 'Classification Duration NN' does not exist. Creating a new experiment.\n",
      "2025/02/22 19:22:20 INFO mlflow.tracking.fluent: Autologging successfully enabled for keras.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution des classes dans l'ensemble d'entraînement :\n",
      "4    23.744554\n",
      "2    20.150495\n",
      "0    19.716832\n",
      "3    18.817822\n",
      "1    17.570297\n",
      "Name: proportion, dtype: float64\n",
      "Distribution des classes dans l'ensemble de test :\n",
      "4    23.744654\n",
      "2    20.148899\n",
      "0    19.721210\n",
      "3    18.818311\n",
      "1    17.566925\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/22 19:22:20 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2025/02/22 19:22:20 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n",
      "2025/02/22 19:22:20 WARNING mlflow.spark: With Pyspark >= 3.2, PYSPARK_PIN_THREAD environment variable must be set to false for Spark datasource autologging to work.\n",
      "2025/02/22 19:22:20 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
      "2025/02/22 19:22:21 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh(<full-path-to-git-executable>)\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n",
      "/.local/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-02-22 19:22:21.482426: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import pymongo\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "from mlflow.tracking import MlflowClient\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# --- Connexion à MongoDB ---\n",
    "uri = \"mongodb://mongodb:27017/\"\n",
    "client = pymongo.MongoClient(uri)\n",
    "db = client[\"github_issues\"]\n",
    "collection = db[\"closed_issues\"]\n",
    "\n",
    "# --- Extraction des données depuis MongoDB ---\n",
    "data = []\n",
    "for issue in collection.find({\"duration_class\": {\"$exists\": True}}):\n",
    "    title = issue.get(\"title\", \"\")\n",
    "    body = issue.get(\"body\", \"\")\n",
    "    language = issue.get(\"language\", \"unknown\")\n",
    "    duration_class = issue.get(\"duration_class\", \"unknown\")\n",
    "    text = title + \" \" + body\n",
    "    data.append([text, language, duration_class])\n",
    "\n",
    "# --- Conversion en DataFrame ---\n",
    "df = pd.DataFrame(data, columns=[\"text\", \"language\", \"duration_class\"])\n",
    "print(\"Distribution des classes dans l'ensemble complet :\")\n",
    "print(df[\"duration_class\"].value_counts(normalize=True) * 100)\n",
    "\n",
    "# --- Préparation des features et labels ---\n",
    "X = df[\"text\"]\n",
    "y = df[\"duration_class\"]\n",
    "\n",
    "# --- Vectorisation avec TF-IDF ---\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "print(\"Shape of TF-IDF features:\", X_tfidf.shape)\n",
    "\n",
    "# --- Ajout de la langue comme feature catégorielle ---\n",
    "LANGUAGE_COLUMNS = [\"Python\", \"Java\", \"JavaScript\", \"C++\", \"Ruby\", \"Go\", \"PHP\", \"Other\"]\n",
    "\n",
    "# Encodage one-hot de la langue et réindexation\n",
    "X_language = pd.get_dummies(df[\"language\"]).reindex(columns=LANGUAGE_COLUMNS, fill_value=0)\n",
    "print(\"Shape of dense language features:\", X_language.shape)\n",
    "\n",
    "# Conversion en matrice sparse\n",
    "X_language_sparse = sp.csr_matrix(X_language.to_numpy().astype(float))\n",
    "print(\"Shape of sparse language features:\", X_language_sparse.shape)\n",
    "\n",
    "# Combinaison des features TF-IDF et langue\n",
    "X_final = sp.hstack([X_tfidf, X_language_sparse])\n",
    "print(\"Shape of combined features:\", X_final.shape)\n",
    "\n",
    "# Conversion en tableau dense pour le réseau de neurones\n",
    "X_final_dense = X_final.toarray()\n",
    "\n",
    "# --- Encodage des labels ---\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "num_classes = len(le.classes_)\n",
    "y_categorical = to_categorical(y_encoded, num_classes=num_classes)\n",
    "\n",
    "# --- Séparation train/test ---\n",
    "X_train, X_test, y_train, y_test, y_train_enc, y_test_enc = train_test_split(\n",
    "    X_final_dense, y_categorical, y_encoded, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(\"Distribution des classes dans l'ensemble d'entraînement :\")\n",
    "print(pd.Series(y_train_enc).value_counts(normalize=True) * 100)\n",
    "print(\"Distribution des classes dans l'ensemble de test :\")\n",
    "print(pd.Series(y_test_enc).value_counts(normalize=True) * 100)\n",
    "\n",
    "# --- Configuration de MLflow ---\n",
    "mlflow.set_tracking_uri(\"../mlruns\")  # Ajustez le chemin si nécessaire\n",
    "mlflow.set_experiment(\"Classification Duration NN\")\n",
    "mlflow.autolog()  # Activer l'autologging\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    # --- Construction du modèle de réseau de neurones ---\n",
    "    input_dim = X_final_dense.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_dim=input_dim))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # --- Entraînement du modèle ---\n",
    "    history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "    \n",
    "    # --- Évaluation du modèle ---\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(\"Test accuracy:\", accuracy)\n",
    "    \n",
    "    # Génération des prédictions pour le rapport de classification\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "    print(classification_report(y_test_enc, y_pred, target_names=le.classes_))\n",
    "    \n",
    "    # --- Sauvegarde locale du modèle, vectorizer et label encoder ---\n",
    "    model_dir = \"../models\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    model_path = os.path.join(model_dir, \"nn_model.h5\")\n",
    "    model.save(model_path)\n",
    "    vectorizer_path = os.path.join(model_dir, \"tfidf_vectorizer.pkl\")\n",
    "    joblib.dump(vectorizer, vectorizer_path)\n",
    "    labelencoder_path = os.path.join(model_dir, \"label_encoder.pkl\")\n",
    "    joblib.dump(le, labelencoder_path)\n",
    "    \n",
    "    # --- Log du modèle et des artefacts avec MLflow ---\n",
    "    mlflow.keras.log_model(model, artifact_path=\"nn_model\")\n",
    "    mlflow.log_artifact(model_path)\n",
    "    \n",
    "    # --- Enregistrement du modèle dans le MLflow Model Registry ---\n",
    "    model_uri = f\"runs:/{run.info.run_id}/nn_model\"\n",
    "    registered_model = mlflow.register_model(model_uri, \"MyNNModel\")\n",
    "    print(\"Modèle enregistré dans le registre avec la version:\", registered_model.version)\n",
    "    \n",
    "    # --- Transition du modèle vers l'état 'Production' ---\n",
    "    mlflow_client = MlflowClient()\n",
    "    mlflow_client.transition_model_version_stage(\n",
    "        name=\"MyNNModel\",\n",
    "        version=registered_model.version,\n",
    "        stage=\"Production\"\n",
    "    )\n",
    "    print(\"Le modèle a été mis en production.\")\n",
    "\n",
    "print(\"Modèle logué et enregistré dans MLflow avec le run ID:\", run.info.run_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

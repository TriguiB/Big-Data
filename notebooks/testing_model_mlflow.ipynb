{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution des classes dans l'ensemble complet :\n",
      "duration_class\n",
      "5    23.744574\n",
      "3    20.150176\n",
      "1    19.717707\n",
      "4    18.817920\n",
      "2    17.569623\n",
      "Name: proportion, dtype: float64\n",
      "Shape of TF-IDF features: (63126, 5000)\n",
      "Shape of dense language features: (63126, 8)\n",
      "Shape of sparse language features: (63126, 8)\n",
      "Shape of combined features: (63126, 5008)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/22 19:24:58 INFO mlflow.tracking.fluent: Experiment with name 'Classification Duration' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution des classes dans l'ensemble d'entraînement :\n",
      "duration_class\n",
      "5    23.744554\n",
      "3    20.150495\n",
      "1    19.716832\n",
      "4    18.817822\n",
      "2    17.570297\n",
      "Name: proportion, dtype: float64\n",
      "Distribution des classes dans l'ensemble de test :\n",
      "duration_class\n",
      "5    23.744654\n",
      "3    20.148899\n",
      "1    19.721210\n",
      "4    18.818311\n",
      "2    17.566925\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/22 19:24:58 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2025/02/22 19:24:58 WARNING mlflow.spark: With Pyspark >= 3.2, PYSPARK_PIN_THREAD environment variable must be set to false for Spark datasource autologging to work.\n",
      "2025/02/22 19:24:58 INFO mlflow.tracking.fluent: Autologging successfully enabled for pyspark.\n",
      "2025/02/22 19:25:00 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'toarray'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.34      0.31      2490\n",
      "           2       0.20      0.10      0.13      2218\n",
      "           3       0.24      0.23      0.24      2544\n",
      "           4       0.25      0.18      0.21      2376\n",
      "           5       0.34      0.49      0.40      2998\n",
      "\n",
      "    accuracy                           0.28     12626\n",
      "   macro avg       0.26      0.27      0.26     12626\n",
      "weighted avg       0.27      0.28      0.27     12626\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/02/22 19:26:19 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Successfully registered model 'MyLogisticModel'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle enregistré dans le registre avec la version: 1\n",
      "Le modèle a été mis en production.\n",
      "Modèle logué et enregistré dans MLflow avec le run ID: 9625c07c3b2d4f3ca23d3024c4783999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'MyLogisticModel'.\n",
      "/tmp/ipykernel_3682/2800596505.py:101: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  mlflow_client.transition_model_version_stage(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import pymongo\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# --- Connexion à MongoDB ---\n",
    "uri = \"mongodb://mongodb:27017/\"\n",
    "client = pymongo.MongoClient(uri)\n",
    "db = client[\"github_issues\"]\n",
    "collection = db[\"closed_issues\"]\n",
    "\n",
    "# --- Extraction des données depuis MongoDB ---\n",
    "data = []\n",
    "for issue in collection.find({\"duration_class\": {\"$exists\": True}}):\n",
    "    title = issue.get(\"title\", \"\")\n",
    "    body = issue.get(\"body\", \"\")\n",
    "    language = issue.get(\"language\", \"unknown\")\n",
    "    duration_class = issue.get(\"duration_class\", \"unknown\")\n",
    "    text = title + \" \" + body\n",
    "    data.append([text, language, duration_class])\n",
    "\n",
    "# --- Conversion en DataFrame ---\n",
    "df = pd.DataFrame(data, columns=[\"text\", \"language\", \"duration_class\"])\n",
    "print(\"Distribution des classes dans l'ensemble complet :\")\n",
    "print(df[\"duration_class\"].value_counts(normalize=True) * 100)\n",
    "\n",
    "# --- Préparation des features et labels ---\n",
    "X = df[\"text\"]\n",
    "y = df[\"duration_class\"]\n",
    "\n",
    "# --- Vectorisation avec TF-IDF ---\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "print(\"Shape of TF-IDF features:\", X_tfidf.shape)\n",
    "\n",
    "# --- Ajout de la langue comme feature catégorielle ---\n",
    "LANGUAGE_COLUMNS = [\"Python\", \"Java\", \"JavaScript\", \"C++\", \"Ruby\", \"Go\", \"PHP\", \"Other\"]\n",
    "\n",
    "# One-hot encode and reindex to ensure consistent columns\n",
    "X_language = pd.get_dummies(df[\"language\"]).reindex(columns=LANGUAGE_COLUMNS, fill_value=0)\n",
    "print(\"Shape of dense language features:\", X_language.shape)\n",
    "\n",
    "# Convert the dense language feature array to a sparse matrix (cast to float for consistency)\n",
    "X_language_sparse = sp.csr_matrix(X_language.to_numpy().astype(float))\n",
    "print(\"Shape of sparse language features:\", X_language_sparse.shape)\n",
    "\n",
    "# Combine the TF-IDF features and the language features\n",
    "X_final = sp.hstack([X_tfidf, X_language_sparse])\n",
    "print(\"Shape of combined features:\", X_final.shape)\n",
    "\n",
    "# --- Séparation train/test ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_final, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(\"Distribution des classes dans l'ensemble d'entraînement :\")\n",
    "print(pd.Series(y_train).value_counts(normalize=True) * 100)\n",
    "print(\"Distribution des classes dans l'ensemble de test :\")\n",
    "print(pd.Series(y_test).value_counts(normalize=True) * 100)\n",
    "\n",
    "# --- Configuration de MLflow ---\n",
    "mlflow.set_tracking_uri(\"../mlruns\")  # Ajustez le chemin si nécessaire\n",
    "mlflow.set_experiment(\"Classification Duration\")\n",
    "mlflow.autolog()  # Activer l'autologging\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    # --- Entraînement du modèle ---\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # --- Évaluation du modèle ---\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # --- Sauvegarde locale du modèle et du vectorizer ---\n",
    "    model_dir = \"../models\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    model_path = os.path.join(model_dir, \"logistic_model.pkl\")\n",
    "    joblib.dump(model, model_path)\n",
    "    vectorizer_path = os.path.join(model_dir, \"tfidf_vectorizer.pkl\")\n",
    "    joblib.dump(vectorizer, vectorizer_path)\n",
    "    \n",
    "    # --- Log du modèle et des artefacts avec MLflow ---\n",
    "    mlflow.sklearn.log_model(model, artifact_path=\"logistic_model\")\n",
    "    mlflow.log_artifact(model_path)\n",
    "    \n",
    "    # --- Enregistrement du modèle dans le MLflow Model Registry ---\n",
    "    model_uri = f\"runs:/{run.info.run_id}/logistic_model\"\n",
    "    registered_model = mlflow.register_model(model_uri, \"MyLogisticModel\")\n",
    "    print(\"Modèle enregistré dans le registre avec la version:\", registered_model.version)\n",
    "    \n",
    "    # --- Transition du modèle vers l'état 'Production' ---\n",
    "    mlflow_client = MlflowClient()\n",
    "    mlflow_client.transition_model_version_stage(\n",
    "        name=\"MyLogisticModel\",\n",
    "        version=registered_model.version,\n",
    "        stage=\"Production\"\n",
    "    )\n",
    "    print(\"Le modèle a été mis en production.\")\n",
    "\n",
    "print(\"Modèle logué et enregistré dans MLflow avec le run ID:\", run.info.run_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

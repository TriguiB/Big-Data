{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import random\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, avg, desc\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Connexion à MongoDB\n",
    "uri = \"mongodb://mongodb:27017/\"\n",
    "client = pymongo.MongoClient(uri)\n",
    "db = client[\"github_issues\"]\n",
    "collection = db[\"closed_issues\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "      <th>duration_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Errors occured when trying to run sniffnet: in...</td>\n",
       "      <td>Rust</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thread 'thread_write_report' panic when run no...</td>\n",
       "      <td>Rust</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unable to install on Windows 11 ARM64 VM insta...</td>\n",
       "      <td>Rust</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The \"Open full report\" button might resize awk...</td>\n",
       "      <td>Rust</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Include WPCAP on installation? wpcap can be a ...</td>\n",
       "      <td>Rust</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text language  duration_class\n",
       "0  Errors occured when trying to run sniffnet: in...     Rust               2\n",
       "1  thread 'thread_write_report' panic when run no...     Rust               5\n",
       "2  unable to install on Windows 11 ARM64 VM insta...     Rust               5\n",
       "3  The \"Open full report\" button might resize awk...     Rust               5\n",
       "4  Include WPCAP on installation? wpcap can be a ...     Rust               5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraire les données\n",
    "cursor = collection.find({\"duration\": {\"$exists\": True}})\n",
    "\n",
    "data = []\n",
    "for issue in cursor:\n",
    "    title = issue[\"title\"]\n",
    "    body = issue[\"body\"]\n",
    "    language = issue[\"language\"]\n",
    "    duration_class = issue[\"duration_class\"]\n",
    "    \n",
    "    # Vous pouvez concaténer le titre et le body pour un meilleur modèle\n",
    "    text = title + \" \" + body\n",
    "    data.append([text, language, duration_class])\n",
    "\n",
    "# Convertir en DataFrame\n",
    "df = pd.DataFrame(data, columns=[\"text\", \"language\", \"duration_class\"])\n",
    "\n",
    "# Afficher les premières lignes du DataFrame pour vérifier les données\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répartition des classes dans l'ensemble complet :\n",
      "duration_class\n",
      "5    23.744574\n",
      "3    20.150176\n",
      "1    19.717707\n",
      "4    18.817920\n",
      "2    17.569623\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Afficher la distribution des classes dans l'ensemble de données complet\n",
    "class_distribution = df['duration_class'].value_counts(normalize=True) * 100\n",
    "print(\"Répartition des classes dans l'ensemble complet :\")\n",
    "print(class_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions de X_final : (63126, 5013)\n"
     ]
    }
   ],
   "source": [
    "# Prétraiter les données\n",
    "X = df[\"text\"]\n",
    "y = df[\"duration_class\"]\n",
    "\n",
    "# Vectoriser le texte avec TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "# Ajouter la colonne de langue en tant que feature\n",
    "X_language = pd.get_dummies(df[\"language\"])\n",
    "\n",
    "# Fusionner les caractéristiques textuelles et celles liées au langage\n",
    "import scipy.sparse as sp\n",
    "X_final = sp.hstack([X_tfidf, X_language.values])\n",
    "\n",
    "# Afficher les dimensions de la matrice résultante\n",
    "print(f\"Dimensions de X_final : {X_final.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répartition des classes dans l'ensemble d'entraînement :\n",
      "duration_class\n",
      "5    23.766337\n",
      "3    20.158416\n",
      "1    19.764356\n",
      "4    18.778218\n",
      "2    17.532673\n",
      "Name: proportion, dtype: float64\n",
      "Répartition des classes dans l'ensemble de test :\n",
      "duration_class\n",
      "5    23.657532\n",
      "3    20.117218\n",
      "1    19.531126\n",
      "4    18.976715\n",
      "2    17.717409\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Afficher la distribution des classes dans les ensembles d'entraînement et de test\n",
    "print(\"Répartition des classes dans l'ensemble d'entraînement :\")\n",
    "print(y_train.value_counts(normalize=True) * 100)\n",
    "\n",
    "print(\"Répartition des classes dans l'ensemble de test :\")\n",
    "print(y_test.value_counts(normalize=True) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métriques de classification sur l'ensemble de test :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.38      0.33      2466\n",
      "           2       0.22      0.11      0.14      2237\n",
      "           3       0.24      0.21      0.22      2540\n",
      "           4       0.26      0.19      0.22      2396\n",
      "           5       0.34      0.49      0.40      2987\n",
      "\n",
      "    accuracy                           0.29     12626\n",
      "   macro avg       0.27      0.28      0.26     12626\n",
      "weighted avg       0.27      0.29      0.27     12626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Entraîner un modèle de régression logistique\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédire sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Évaluer les résultats\n",
    "print(\"Métriques de classification sur l'ensemble de test :\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Class  Precision    Recall  F1-Score\n",
      "0      1   0.300842  0.376723  0.334534\n",
      "1      2   0.215971  0.106392  0.142558\n",
      "2      3   0.235189  0.206299  0.219799\n",
      "3      4   0.258029  0.194491  0.221799\n",
      "4      5   0.335756  0.494811  0.400054\n"
     ]
    }
   ],
   "source": [
    "# Afficher les métriques de chaque classe séparément\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "precision, recall, fscore, _ = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "\n",
    "# Créer un DataFrame avec les résultats\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Class': sorted(y_test.unique()),\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': fscore\n",
    "})\n",
    "\n",
    "# Afficher les métriques pour chaque classe\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class  is: 4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "# Test example issue\n",
    "test_example = [\"Error after inserting an extern file\", \n",
    "                \"Cant build the app /.\", \n",
    "                \"Java\"]\n",
    "\n",
    "# Preprocess the text of the example\n",
    "test_text = test_example[0] + \" \" + test_example[1]  # Combine title and description\n",
    "test_language = test_example[2]  # Language\n",
    "\n",
    "# Vectorize the text of the example using the same vectorizer as the training phase\n",
    "test_tfidf = vectorizer.transform([test_text])\n",
    "\n",
    "# Convert the language feature into the same format as the training set (one-hot encoding)\n",
    "test_language_feature = pd.get_dummies([test_language]).reindex(columns=X_language.columns, fill_value=0)\n",
    "\n",
    "# Convert to a numeric array (integer dtype)\n",
    "test_language_feature = test_language_feature.values.astype(int)\n",
    "\n",
    "# Convert to sparse matrix format\n",
    "test_language_feature_sparse = sparse.csr_matrix(test_language_feature)\n",
    "\n",
    "# Combine text and language features into a sparse matrix (same as during training)\n",
    "test_input = sparse.hstack([test_tfidf, test_language_feature_sparse])\n",
    "\n",
    "# Make a prediction using the trained model\n",
    "predicted_class = model.predict(test_input)\n",
    "\n",
    "# Print the predicted class (duration interval)\n",
    "print(f\"The predicted class  is: {predicted_class[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
